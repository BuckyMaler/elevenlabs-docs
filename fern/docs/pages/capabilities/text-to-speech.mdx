---
title: Text to speech
subtitle: Learn how to turn text into human-like spoken audio with ElevenLabs.
---

## Overview

ElevenLabs [Text to Speech (TTS)](/docs/api-reference/text-to-speech) API turns text into lifelike audio with nuanced intonation, pacing and emotional awareness. [Our models](/docs/models) adapt to textual cues across 32 languages and multiple voice styles and can be used to:

- Narrate global media campaigns & ads
- Produce audiobooks in multiple languages with complex emotional delivery
- Stream real-time audio from text

Listen to a sample:

<elevenlabs-audio-player
    audio-title="George"
    audio-src="https://storage.googleapis.com/eleven-public-cdn/audio/marketing/george.mp3"
/>

Explore our [Voice Library](https://elevenlabs.io/community) to find the perfect voice for your project.

## Quickstart

The `text-to-speech` endpoint converts text into natural-sounding speech using three core parameters:

- `model_id`: Determines the quality, speed, and language support
- `voice_id`: Specifies which voice to use (explore our [Voice Library](https://elevenlabs.io/community))
- `text`: The input text to be converted to speech
- `output_format`: Determines the audio format, quality, sampling rate & bitrate

Execute the code below to generate your first text-to-speech audio:

<CodeBlocks>

```python title="Python" focus={5-11}
from elevenlabs.client import ElevenLabs
from elevenlabs import play

client = ElevenLabs()
audio = client.text_to_speech.convert(
    text="The first move is what sets everything in motion.",
    voice_id="JBFqnCBsd6RMkjVDRZzb",
    model_id="eleven_multilingual_v2",
    output_format="mp3_44100_128",
)

play(audio)
```

```javascript title="JavaScript" focus={4-8}
import { ElevenLabsClient, play } from 'elevenlabs';

const client = new ElevenLabsClient();
const audio = await client.textToSpeech.convert('JBFqnCBsd6RMkjVDRZzb', {
  text: 'The first move is what sets everything in motion.',
  model_id: 'eleven_multilingual_v2',
  output_format: 'mp3_44100_128',
});

await play(audio);
```

```bash title="cURL"
curl -X POST "https://api.elevenlabs.io/v1/text-to-speech/JBFqnCBsd6RMkjVDRZzb?output_format=mp3_44100_128" \
    -H "Xi-Api-Key: <apiKey>" \
    -H "Content-Type: application/json" \
    -d '{
        "text": "The first move is what sets everything in motion.",
        "model_id": "eleven_multilingual_v2"
    }' \
    --output audio.mp3
```

</CodeBlocks>

### Voice quality

For real-time applications, Flash v2.5 provides ultra-low 75ms latency optimized for streaming, while Multilingual v2 delivers the highest quality audio with more nuanced expression.

Learn more about our [models](/docs/models).

### Voice options

ElevenLabs offers thousands of voices across 32 languages through multiple creation methods:

- [Voice Library](/docs/voice-library) with 3,000+ community-shared voices
- [Professional Voice Cloning](/docs/voice-cloning/professional) for highest-fidelity replicas
- [Instant Voice Cloning](/docs/voice-cloning/instant) for quick voice replication
- [Voice Design](/docs/voice-design) to generate custom voices from text descriptions

Learn more about our [voice creation options](/docs/voices).

### Streaming audio

The Text to Speech API provides support for real time audio streaming using [chunk transfer encoding](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Transfer-Encoding). This means that the audio is able to be played before the full file has been generated and made accessible.

<CodeBlocks>

```python title="Python" focus={5-11} maxLines=10
from elevenlabs import stream
from elevenlabs.client import ElevenLabs

client = ElevenLabs()
audio_stream = client.text_to_speech.convert_as_stream(
    text="The first move is what sets everything in motion.",
    voice_id="JBFqnCBsd6RMkjVDRZzb",
    model_id="eleven_multilingual_v2",
    output_format="mp3_44100_128",
)

# option 1: play the streamed audio locally
stream(audio_stream)

# option 2: process the audio bytes manually
for chunk in audio_stream:
    if isinstance(chunk, bytes):
        print(chunk)
```

```javascript title="JavaScript" focus={6-11} maxLines=10
import { ElevenLabsClient, stream } from 'elevenlabs';
import { Readable } from 'stream';

const client = new ElevenLabsClient();
async function main() {
  const audioStream = await client.textToSpeech.convertAsStream('JBFqnCBsd6RMkjVDRZzb', {
    text: 'The first move is what sets everything in motion.',
    model_id: 'eleven_multilingual_v2',
    output_format: 'mp3_44100_128',
  });

  // option 1: play the streamed audio locally
  await stream(Readable.from(audioStream));

  // option 2: process the audio manually
  for await (const chunk of audioStream) {
    console.log(chunk);
  }
}

main();
```

</CodeBlocks>

## Supported formats

The default response format is "mp3", but other formats like "PCM", & "μ-law" are available.

- **MP3**
  - Sample rates: 22.05kHz - 44.1kHz
  - Bitrates: 32kbps - 192kbps
  - **Note**: Higher quality options require Creator tier or higher
- **PCM (S16LE)**
  - Sample rates: 16kHz - 44.1kHz
  - **Note**: Higher quality options require Pro tier or higher
- **μ-law**
  - 8kHz sample rate
  - Optimized for telephony applications

<Success>
  Higher quality audio options are only available on paid tiers - see our [pricing
  page](https://elevenlabs.io/pricing) for details.
</Success>

## Supported languages

Multilingual v2 supports 29 languages:

<Markdown src="/snippets/multilingual-v2-languages.mdx" />

Flash v2.5 supports 32 languages - all languages from Multilingual v2 plus:

_Hungarian, Norwegian, Vietnamese_

Simply input text in any of our supported languages and select a matching voice from our [Voice Library](https://elevenlabs.io/community). For the most natural results, choose a voice with an accent that matches your target language and region.

## FAQ

<AccordionGroup>
  <Accordion title="Can I fine-tune the emotional range of the generated audio?">
    The models interpret emotional context directly from the text input. For example, adding
    descriptive text like "she said excitedly" or using exclamation marks will influence the speech
    emotion. Voice settings like Stability and Similarity help control the consistency, while the
    underlying emotion comes from textual cues.
  </Accordion>
  <Accordion title="Can I clone my own voice or a specific speaker's voice?">
    Yes. Instant Voice Cloning quickly mimics another speaker from short clips. For high-fidelity
    clones, check out our Professional Voice Clone.
  </Accordion>
  <Accordion title="Do I own the audio output?">
    Yes. You retain ownership of any audio you generate. However, commercial usage rights are only
    available with paid plans. With a paid subscription, you may use generated audio for commercial
    purposes and monetize the outputs if you own the IP rights to the input content.
  </Accordion>
  <Accordion title="How do I reduce latency for real-time cases?">
    Use the low-latency Flash models (Flash v2 or v2.5) optimized for near real-time conversational
    or interactive scenarios. See our [latency optimization guide](/docs/latency-optimization) for
    more details.
  </Accordion>
  <Accordion title="Why is my output sometimes inconsistent?">
    The models are nondeterministic. For consistency, use the optional seed parameter, though subtle
    differences may still occur.
  </Accordion>
  <Accordion title="What's the best practice for large text conversions?">
    Split long text into segments and use streaming for real-time playback and efficient processing.
    To maintain natural prosody flow between chunks, use `previous_text` or `previous_request_ids`.
  </Accordion>
</AccordionGroup>
