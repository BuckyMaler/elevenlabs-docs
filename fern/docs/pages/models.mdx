---
title: Models
---

## Flagship models

<Markdown src="/snippets/models.mdx" />
<div className="text-center">
  <div>[Pricing](https://elevenlabs.io/pricing)</div>
</div>

## Models overview

The ElevenLabs API offers a range of speech synthesis models optimized for different use cases, quality levels, and performance requirements.

| Model ID                     | Description                                                          | Languages |
| ---------------------------- | -------------------------------------------------------------------- | --------- |
| `eleven_multilingual_v2`     | Our most lifelike model with rich emotional expression               | 29        |
| `eleven_flash_v2_5`          | Ultra-fast model optimized for real-time use (~75ms&dagger;)         | 32        |
| `eleven_flash_v2`            | Ultra-fast model optimized for real-time use (~75ms&dagger;)         | English   |
| `eleven_multilingual_sts_v2` | State-of-the-art multilingual voice changer model (Speech to Speech) | 29        |
| `eleven_english_sts_v2`      | English-only voice changer model (Speech to Speech)                  | English   |

<Accordion title="Older Models">

<Warning>

These models are maintained for backward compatibility but are not recommended for new projects.

</Warning>

| Model ID                 | Description                                                                 | Languages |
| ------------------------ | --------------------------------------------------------------------------- | --------- |
| `eleven_monolingual_v1`  | First generation TTS model (outclassed by v2 models)                        | English   |
| `eleven_multilingual_v1` | First multilingual model (outclassed by v2 models)                          | 9         |
| `eleven_turbo_v2_5`      | High quality, low-latency model (~250ms-300ms) (outclassed by Flash models) | 32        |
| `eleven_turbo_v2`        | High quality, low-latency model (~250ms-300ms) (outclassed by Flash models) | English   |

</Accordion>

## Multilingual v2

Eleven Multilingual v2 is our most advanced, emotionally-aware speech synthesis model. It produces natural, lifelike speech with high emotional range and contextual understanding across multiple languages.

The model delivers consistent voice quality and personality across all supported languages while maintaining the speaker's unique characteristics and accent.

This model excels in scenarios requiring high-quality, emotionally nuanced speech:

- **Audiobook Production**: Perfect for long-form narration with complex emotional delivery
- **Character Voiceovers**: Ideal for gaming and animation due to its emotional range
- **Professional Content**: Well-suited for corporate videos and e-learning materials
- **Multilingual Projects**: Maintains consistent voice quality across language switches

While it has a higher latency & cost per character than Flash models, it delivers superior quality for projects where lifelike speech is important.

## Flash v2.5

Eleven Flash v2.5 is our fastest speech synthesis model, designed for real-time applications and conversational AI. It delivers high-quality speech with ultra-low latency (~75ms&dagger;) across 32 languages.

The model balances speed and quality, making it ideal for interactive applications while maintaining natural-sounding output and consistent voice characteristics across languages.

This model is particularly well-suited for:

- **Conversational AI**: Perfect for real-time voice agents and chatbots
- **Interactive Applications**: Ideal for games and applications requiring immediate response
- **Large-Scale Processing**: Efficient for bulk text-to-speech conversion

With its lower price point and 75ms latency, Flash v2.5 is the cost-effective choice for developers needing fast, reliable speech synthesis across multiple languages.

<Frame background="subtle">
  <img src="/assets/images/model-latency-tradeoff.webp" />
</Frame>

## Model selection guide

<AccordionGroup>
  <Accordion title="Requirements">
    <CardGroup cols={1}>
      <Card title="Quality">
        Use `eleven_multilingual_v2`
        
        Best for high-fidelity audio output with rich emotional expression
      </Card>
      <Card title="Low-latency">
        Use Flash models

        Optimized for real-time applications (~75ms latency)
      </Card>
      <Card title="Multilingual">
        Use either either `eleven_multilingual_v2` or `eleven_flash_v2_5`

        Both support up to 32 languages
      </Card>
    </CardGroup>

  </Accordion>

  <Accordion title="Use case">
    <CardGroup cols={1}>
      <Card title="Content creation">
        Use `eleven_multilingual_v2`
      
        Ideal for professional content, audiobooks & video narration.
      </Card>

      <Card title="Conversational AI">
        Use `eleven_flash_v2_5`, `eleven_flash_v2` or `eleven_multilingual_v2`

        Perfect for real-time conversational applications
      </Card>

      <Card title="Voice changer">
        Use `eleven_multilingual_sts_v2`

        Specialized for Speech-to-Speech conversion
      </Card>
    </CardGroup>

  </Accordion>
</AccordionGroup>

### Supported languages

<Markdown src="/snippets/v2-model-languages.mdx" />

<Markdown src="/snippets/v2-5-model-languages.mdx" />

<Note>
  For detailed information and troubleshooting guidance, refer to our [help
  center](https://help.elevenlabs.io).
</Note>

&dagger; Excluding application & network latency
